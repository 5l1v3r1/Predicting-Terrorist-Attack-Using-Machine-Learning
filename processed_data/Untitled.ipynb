{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Title:       Build a preprocessing pipeline that helps user preprocess training\n",
    "             and test data from the corresponding CSV input files.\n",
    "\n",
    "Description: Fill in missing values, discretize continuous variables, generate\n",
    "             new features, deal with categorical variables with multiple levels,\n",
    "             scale data, and save preprocessed data.\n",
    "\n",
    "Author:      Kunyu He, CAPP'20, The University of Chicago\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------#\n",
    "INPUT_DIR = \"\"\n",
    "OUTPUT_DIR = \"\"\n",
    "LOG_DIR = \"../logs/featureEngineering/\"\n",
    "\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "TRAIN_FEATURES_FILE = 'train_features.txt'\n",
    "TEST_FEATURES_FILE = 'test_features.txt'\n",
    "\n",
    "# logging\n",
    "logger= logging.getLogger('featureEngineering')\n",
    "logger.setLevel(logging.INFO)\n",
    "ch = logging.StreamHandler()\n",
    "logger.addHandler(ch)\n",
    "fh = logging.FileHandler(LOG_DIR + time.strftime(\"%Y%m%d-%H%M%S\") + '.log')\n",
    "logger.addHandler(fh)\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name, drop_na=False):\n",
    "    \"\"\"\n",
    "    Read credit data in the .csv file and data types from the .json file.\n",
    "\n",
    "    Inputs:\n",
    "        - data_file (string): name of the data file.\n",
    "        - drop_na (bool): whether to drop rows with any missing values\n",
    "\n",
    "    Returns:\n",
    "        (DataFrame) clean data set with correct data types\n",
    "\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(INPUT_DIR + file_name)\n",
    "\n",
    "    if drop_na:\n",
    "        data.dropna(axis=0, inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['elevation', 'DIS_LAKE', 'DIS_MAJOR_RIVER', 'DIS_OCEAN', 'DIS_RIVER',\n",
       "       'PRECAVNEW80_08', 'TEMPAV_8008', 'ethin_div', 'HighRelig', 'ChrCatP',\n",
       "       'ReligCatP', 'year', 'loc_id', 'MER_40', 'POPGPW_40', 'attacked',\n",
       "       'nkill_past_5', 'nwound_past_5', 'attacktype_past_5',\n",
       "       'targettype_past_5', 'group_name_past_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "elevation             0\n",
       "DIS_LAKE              7\n",
       "DIS_MAJOR_RIVER       7\n",
       "DIS_OCEAN             7\n",
       "DIS_RIVER             7\n",
       "PRECAVNEW80_08       18\n",
       "TEMPAV_8008          18\n",
       "ethin_div             0\n",
       "HighRelig             0\n",
       "ChrCatP               0\n",
       "ReligCatP             0\n",
       "year                  0\n",
       "loc_id                0\n",
       "MER_40               76\n",
       "POPGPW_40             0\n",
       "attacked              0\n",
       "nkill_past_5          0\n",
       "nwound_past_5         0\n",
       "attacktype_past_5     0\n",
       "targettype_past_5     0\n",
       "group_name_past_5     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95-100%    368\n",
       "60-75%     146\n",
       "75-85%     122\n",
       "90-95%     100\n",
       "85-90%      77\n",
       "40-60%      70\n",
       "10-40%       6\n",
       "Name: ReligCatP, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.ReligCatP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
